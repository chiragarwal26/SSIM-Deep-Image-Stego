{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f1585036-dd20-497d-ab1b-c9725ed0f56c",
      "metadata": {
        "id": "f1585036-dd20-497d-ab1b-c9725ed0f56c"
      },
      "source": [
        "# Importing the necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f1d8fe8-8bb0-43ae-8354-02f61d9e0455",
      "metadata": {
        "id": "5f1d8fe8-8bb0-43ae-8354-02f61d9e0455"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76fe5273-5293-4265-85a2-7485754fc1d2",
      "metadata": {
        "id": "76fe5273-5293-4265-85a2-7485754fc1d2"
      },
      "outputs": [],
      "source": [
        "pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org --proxy http://snidm:Sdn%40snidm@172.31.7.55:8080 tensorflow-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ee455ef-679d-47ce-8c57-20728f1f7fd0",
      "metadata": {
        "id": "5ee455ef-679d-47ce-8c57-20728f1f7fd0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a4a6001-7896-4bff-944c-abb3499d50e3",
      "metadata": {
        "id": "7a4a6001-7896-4bff-944c-abb3499d50e3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1931ad60-294d-4d6a-9d8b-a0034ef5c3a9",
      "metadata": {
        "id": "1931ad60-294d-4d6a-9d8b-a0034ef5c3a9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6812c963-e122-4a72-98d0-6b3b5f6a9c8b",
      "metadata": {
        "id": "6812c963-e122-4a72-98d0-6b3b5f6a9c8b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b6f55e0-a6b6-4bca-95cf-c5c141bb97b4",
      "metadata": {
        "id": "0b6f55e0-a6b6-4bca-95cf-c5c141bb97b4",
        "outputId": "ab54b6d1-1d20-46ae-ae51-62d99e3d4f3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in c:\\users\\nisg_intern\\appdata\\local\\anaconda3\\lib\\site-packages (10.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org --proxy http://snidm:Sdn%40snidm@172.31.7.55:8080 Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4a43b7c-9b07-494c-8a74-a3a136e672d3",
      "metadata": {
        "scrolled": true,
        "id": "f4a43b7c-9b07-494c-8a74-a3a136e672d3"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "from PIL import Image,ImageOps\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from datetime import datetime\n",
        "from os.path import join"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32bb5d01-5d2e-48cc-b99c-397d4b3bf16c",
      "metadata": {
        "id": "32bb5d01-5d2e-48cc-b99c-397d4b3bf16c"
      },
      "source": [
        "# Some Configuration & Parameters/ Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f76f930b-742c-4cf0-8541-5755b2753917",
      "metadata": {
        "id": "f76f930b-742c-4cf0-8541-5755b2753917"
      },
      "outputs": [],
      "source": [
        "TRAIN_PATH = '/content/sample_data/tarining data'\n",
        "LOGS_Path = \"./logs/\"\n",
        "CHECKPOINTS_PATH = './checkpoints/'\n",
        "\n",
        "# defining parameters\n",
        "BATCH_SIZE = 8\n",
        "LEARNING_RATE = .0001\n",
        "BETA = .75\n",
        "\n",
        "EXP_NAME = f\"beta_{BETA}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a3e7a38-60a8-4800-a444-3a5ce647dc67",
      "metadata": {
        "id": "4a3e7a38-60a8-4800-a444-3a5ce647dc67",
        "outputId": "ecd79758-a712-4f06-b1b2-ac82c9951293"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.test.is_built_with_cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cf05a36-8f60-4b87-8757-caf84ced68ce",
      "metadata": {
        "id": "0cf05a36-8f60-4b87-8757-caf84ced68ce"
      },
      "source": [
        " # Helper Methods to Handle images\n",
        " * The images are first converted to float values between 0 and 1.\n",
        " *\n",
        "Then they are normalised using the Mean and STD fom COCO Dataset.\n",
        " * To undo this normalisation, s, a helper function is also tten.written."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cb68839-e23c-4cad-aa47-391d80901d33",
      "metadata": {
        "id": "7cb68839-e23c-4cad-aa47-391d80901d33"
      },
      "source": [
        "files_list = glob.glob(join(TRAIN_PATH,\"**/*\"))\n",
        "\n",
        "def normalize_batch(imgs):\n",
        "    return (imgs -  np.array([0.485, 0.456, 0.406])) /np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "def denormalize_batch(imgs,should_clip=True):\n",
        "    imgs= (imgs * np.array([0.229, 0.224, 0.225])) + np.array([0.485, 0.456, 0.406])\n",
        "\n",
        "    if should_clip:\n",
        "        imgs= np.clip(imgs,0,1)\n",
        "    return imgs\n",
        "\n",
        "def get_img_batch(files_list,batch_size=32,size=(224,224),should_normalise=True):\n",
        "\n",
        "    batch_cover = []\n",
        "    batch_secret = []\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        img_secret_path = random.choice(files_list)\n",
        "        img_cover_path = random.choice(files_list)\n",
        "\n",
        "        img_secret = Image.open(img_secret_path).convert(\"RGB\")\n",
        "        img_cover = Image.open(img_cover_path).convert(\"RGB\")\n",
        "\n",
        "        img_secret = np.array(ImageOps.fit(img_secret,size),dtype=np.float32)\n",
        "        img_cover = np.array(ImageOps.fit(img_cover,size),dtype=np.float32)\n",
        "\n",
        "        img_secret /= 255.\n",
        "        img_cover /= 255.\n",
        "\n",
        "        batch_cover.append(img_cover)\n",
        "        batch_secret.append(img_secret)\n",
        "\n",
        "    batch_cover,batch_secret = np.array(batch_cover) , np.array(batch_secret)\n",
        "\n",
        "    if should_normalise:\n",
        "        batch_cover = normalize_batch(batch_cover)\n",
        "        batch_secret = normalize_batch(batch_secret)\n",
        "\n",
        "    return batch_cover,batch_secret\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52924f68-6f91-439a-b141-4b3bf2e1ae22",
      "metadata": {
        "id": "52924f68-6f91-439a-b141-4b3bf2e1ae22"
      },
      "source": [
        "# Network Definitions\n",
        "\n",
        "The three networks are identical in terms of structure.\n",
        "\n",
        "The Prepare network takes in the Secret Image and outputssecret50) tensor.\n",
        "\n",
        "The Cover network takes in the output from 1. , and a Cover Image. It concatenates these two tensors , givioutput,153) tensor. Then it performs Convolutions , and outpustego/containerHT,3) image.\n",
        "\n",
        "The Reveal Network Takes in the / Container / Stego output image from Cover Network , and outputs the Revealed Image (which is supposed to look like the Secret Image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6b0431e-580a-4e58-8e24-62cd73ade1b9",
      "metadata": {
        "id": "b6b0431e-580a-4e58-8e24-62cd73ade1b9"
      },
      "source": [
        "# Preparation Network Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e37c9e32-a311-43ea-9803-b6ca69dce3b3",
      "metadata": {
        "id": "e37c9e32-a311-43ea-9803-b6ca69dce3b3"
      },
      "outputs": [],
      "source": [
        "def get_prep_network_op(secret_tensor):\n",
        "    with tf.variable_scope('prep_net'):\n",
        "\n",
        "        with tf.variable_scope(\"7x7_conv_branch\"):\n",
        "            conv_7x7 = tf.keras.layers.Conv2D(filters=75, kernel_size=7, padding='same', name=\"1\", activation=tf.nn.relu)(secret_tensor)\n",
        "            conv_7x7 = tf.keras.layers.Conv2D(filters=75, kernel_size=7, padding='same', name=\"2\", activation=tf.nn.relu)(conv_7x7)\n",
        "            conv_7x7 = tf.keras.layers.Conv2D(filters=75, kernel_size=7, padding='same', name=\"3\", activation=tf.nn.relu)(conv_7x7)\n",
        "            conv_7x7 = tf.keras.layers.Conv2D(filters=75, kernel_size=7, padding='same', name=\"4\", activation=tf.nn.relu)(conv_7x7)\n",
        "\n",
        "        with tf.variable_scope(\"5x5_conv_branch\"):\n",
        "            conv_5x5 = tf.keras.layers.Conv2D(filters=25, kernel_size=5, padding='same', name=\"1\", activation=tf.nn.relu)(secret_tensor)\n",
        "            conv_5x5 = tf.keras.layers.Conv2D(filters=25, kernel_size=5, padding='same', name=\"2\", activation=tf.nn.relu)(conv_5x5)\n",
        "            conv_5x5 = tf.keras.layers.Conv2D(filters=25, kernel_size=5, padding='same', name=\"3\", activation=tf.nn.relu)(conv_5x5)\n",
        "            conv_5x5 = tf.keras.layers.Conv2D(filters=25, kernel_size=5, padding='same', name=\"4\", activation=tf.nn.relu)(conv_5x5)\n",
        "\n",
        "         with tf.variable_scope(\"3x3_conv_branch\"):\n",
        "            conv_3x3 = tf.keras.layers.Conv2D(filters=25, kernel_size=3, padding='same', name=\"1\", activation=tf.nn.relu)(secret_tensor)\n",
        "            conv_3x3 = tf.keras.layers.Conv2D(filters=25, kernel_size=3, padding='same', name=\"2\", activation=tf.nn.relu)(conv_3x3)\n",
        "            conv_3x3 = tf.keras.layers.Conv2D(filters=25, kernel_size=3, padding='same', name=\"3\", activation=tf.nn.relu)(conv_3x3)\n",
        "            conv_3x3 = tf.keras.layers.Conv2D(filters=25, kernel_size=3, padding='same', name=\"4\", activation=tf.nn.relu)(conv_3x3)\n",
        "\n",
        "\n",
        "        concat_1 = tf.concat([conv_7x7, conv_5x5, conv_3x3], axis=3, name='concat_1')\n",
        "\n",
        "        conv_7x7 = tf.keras.layers.Conv2D(filters=75, kernel_size=7, padding='same', name=\"final_7x7\", activation=tf.nn.relu)(concat_1)\n",
        "        conv_5x5 = tf.keras.layers.Conv2D(filters=25, kernel_size=5, padding='same', name=\"final_5x5\", activation=tf.nn.relu)(concat_1)\n",
        "        conv_3x3 = tf.keras.layers.Conv2D(filters=25, kernel_size=3, padding='same', name=\"final_3x3\", activation=tf.nn.relu)(concat_1)\n",
        "\n",
        "        concat_final = tf.concat([conv_7x7, conv_5x5, conv_3x3], axis=3, name='concat_final')\n",
        "\n",
        "        return concat_final\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ccaadd7-79cf-4dae-90c8-458eb844ae15",
      "metadata": {
        "id": "8ccaadd7-79cf-4dae-90c8-458eb844ae15"
      },
      "source": [
        "# Hiding Network Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "287019c6-14eb-4b2c-bc41-53d07b2f987a",
      "metadata": {
        "id": "287019c6-14eb-4b2c-bc41-53d07b2f987a"
      },
      "outputs": [],
      "source": [
        "def get_hiding_network_op(cover_tensor, prep_output):\n",
        "\n",
        "    with tf.variable_scope('hide_net'):\n",
        "        concat_input = tf.concat([cover_tensor, prep_output], axis=3, name='images_features_concat')\n",
        "\n",
        "        with tf.variable_scope(\"7x7_conv_branch\"):\n",
        "            conv_7x7 = tf.keras.layers.Conv2D(filters=75, kernel_size=7, padding='same', name=\"1\", activation=tf.nn.relu)(concat_input)\n",
        "            conv_7x7 = tf.keras.layers.Conv2D(filters=75, kernel_size=7, padding='same', name=\"2\", activation=tf.nn.relu)(conv_7x7)\n",
        "            conv_7x7 = tf.keras.layers.Conv2D(filters=75, kernel_size=7, padding='same', name=\"3\", activation=tf.nn.relu)(conv_7x7)\n",
        "            conv_7x7 = tf.keras.layers.Conv2D(filters=75, kernel_size=7, padding='same', name=\"4\", activation=tf.nn.relu)(conv_7x7)\n",
        "\n",
        "        with tf.variable_scope(\"5x5_conv_branch\"):\n",
        "            conv_5x5 = tf.keras.layers.Conv2D(filters=25, kernel_size=5, padding='same', name=\"1\", activation=tf.nn.relu)(concat_input)\n",
        "            conv_5x5 = tf.keras.layers.Conv2D(filters=25, kernel_size=5, padding='same', name=\"2\", activation=tf.nn.relu)(conv_5x5)\n",
        "            conv_5x5 = tf.keras.layers.Conv2D(filters=25, kernel_size=5, padding='same', name=\"3\", activation=tf.nn.relu)(conv_5x5)\n",
        "            conv_5x5 = tf.keras.layers.Conv2D(filters=25, kernel_size=5, padding='same', name=\"4\", activation=tf.nn.relu)(conv_5x5)\n",
        "\n",
        "        with tf.variable_scope(\"3x3_conv_branch\"):\n",
        "            conv_3x3 = tf.keras.layers.Conv2D(filters=25, kernel_size=3, padding='same', name=\"1\", activation=tf.nn.relu)(concat_input)\n",
        "            conv_3x3 = tf.keras.layers.Conv2D(filters=25, kernel_size=3, padding='same', name=\"2\", activation=tf.nn.relu)(conv_3x3)\n",
        "            conv_3x3 = tf.keras.layers.Conv2D(filters=25, kernel_size=3, padding='same', name=\"3\", activation=tf.nn.relu)(conv_3x3)\n",
        "            conv_3x3 = tf.keras.layers.Conv2D(filters=25, kernel_size=3, padding='same', name=\"4\", activation=tf.nn.relu)(conv_3x3)\n",
        "\n",
        "\n",
        "        concat_1 = tf.concat([conv_7x7, conv_5x5, conv_3x3], axis=3, name='concat_1')\n",
        "\n",
        "        conv_7x7 = tf.keras.layers.Conv2D(filters=75, kernel_size=7, padding='same', name=\"final_7x7\", activation=tf.nn.relu)(concat_1)\n",
        "        conv_5x5 = tf.keras.layers.Conv2D(filters=25, kernel_size=5, padding='same', name=\"final_5x5\", activation=tf.nn.relu)(concat_1)\n",
        "        conv_3x3 = tf.keras.layers.Conv2D(filters=25, kernel_size=3, padding='same', name=\"final_3x3\", activation=tf.nn.relu)(concat_1)\n",
        "\n",
        "        concat_final = tf.concat([conv_7x7, conv_5x5, conv_3x3], axis=3, name='concat_final')\n",
        "        output = tf.keras.layers.Conv2D(filters=3, kernel_size=1, padding='same', name='output')(concat_final)\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b279f8e-a2b1-44b3-89d3-3fa45eac61c2",
      "metadata": {
        "id": "4b279f8e-a2b1-44b3-89d3-3fa45eac61c2"
      },
      "source": [
        "# Reveal / Decoding Network Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c26115a0-4a03-4c5e-9f85-431b9c2d9a7c",
      "metadata": {
        "id": "c26115a0-4a03-4c5e-9f85-431b9c2d9a7c"
      },
      "outputs": [],
      "source": [
        "def get_reveal_network_op(container_tensor):\n",
        "\n",
        "    with tf.variable_scope('reveal_net'):\n",
        "\n",
        "        with tf.variable_scope(\"7x7_conv_branch\"):\n",
        "            conv_7x7 = tf.keras.layers.Conv2D(filters=75, kernel_size=7, padding='same', name=\"1\", activation=tf.nn.relu)(container_tensor)\n",
        "            conv_7x7 = tf.keras.layers.Conv2D(filters=75, kernel_size=7, padding='same', name=\"2\", activation=tf.nn.relu)(conv_7x7)\n",
        "            conv_7x7 = tf.keras.layers.Conv2D(filters=75, kernel_size=7, padding='same', name=\"3\", activation=tf.nn.relu)(conv_7x7)\n",
        "            conv_7x7 = tf.keras.layers.Conv2D(filters=75, kernel_size=7, padding='same', name=\"4\", activation=tf.nn.relu)(conv_7x7)\n",
        "\n",
        "        with tf.variable_scope(\"5x5_conv_branch\"):\n",
        "            conv_5x5 = tf.keras.layers.Conv2D(filters=25, kernel_size=5, padding='same', name=\"1\", activation=tf.nn.relu)(container_tensor)\n",
        "            conv_5x5 = tf.keras.layers.Conv2D(filters=25, kernel_size=5, padding='same', name=\"2\", activation=tf.nn.relu)(conv_5x5)\n",
        "            conv_5x5 = tf.keras.layers.Conv2D(filters=25, kernel_size=5, padding='same', name=\"3\", activation=tf.nn.relu)(conv_5x5)\n",
        "            conv_5x5 = tf.keras.layers.Conv2D(filters=25, kernel_size=5, padding='same', name=\"4\", activation=tf.nn.relu)(conv_5x5)\n",
        "\n",
        "        with tf.variable_scope(\"3x3_conv_branch\"):\n",
        "            conv_3x3 = tf.keras.layers.Conv2D(filters=25, kernel_size=3, padding='same', name=\"1\", activation=tf.nn.relu)(container_tensor)\n",
        "            conv_3x3 = tf.keras.layers.Conv2D(filters=25, kernel_size=3, padding='same', name=\"2\", activation=tf.nn.relu)(conv_3x3)\n",
        "            conv_3x3 = tf.keras.layers.Conv2D(filters=25, kernel_size=3, padding='same', name=\"3\", activation=tf.nn.relu)(conv_3x3)\n",
        "            conv_3x3 = tf.keras.layers.Conv2D(filters=25, kernel_size=3, padding='same', name=\"4\", activation=tf.nn.relu)(conv_3x3)\n",
        "\n",
        "\n",
        "        concat_1 = tf.concat([conv_7x7, conv_5x5, conv_3x3], axis=3, name='concat_1')\n",
        "\n",
        "        conv_5x5 = tf.keras.layers.Conv2D(filters=50, kernel_size=5, padding='same', name=\"final_5x5\", activation=tf.nn.relu)(concat_1)\n",
        "        conv_7x7 = tf.keras.layers.Conv2D(filters=50, kernel_size=7, padding='same', name=\"final_7x7\", activation=tf.nn.relu)(concat_1)\n",
        "        conv_3x3 = tf.keras.layers.Conv2D(filters=50, kernel_size=3, padding='same', name=\"final_3x3\", activation=tf.nn.relu)(concat_1)\n",
        "\n",
        "        concat_final = tf.concat([conv_7x7, conv_5x5, conv_3x3], axis=3, name='concat_final')\n",
        "\n",
        "    output = tf.keras.layers.Conv2D(filters=3, kernel_size=1, padding='same', name='output')(concat_final)\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bf5a640-5d1d-4fd2-9948-432199865c8c",
      "metadata": {
        "id": "1bf5a640-5d1d-4fd2-9948-432199865c8c"
      },
      "source": [
        "# Noise Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "837384e6-cb99-4924-bcc1-c53d729e58df",
      "metadata": {
        "id": "837384e6-cb99-4924-bcc1-c53d729e58df"
      },
      "outputs": [],
      "source": [
        "def get_noise_layer_op(tensor, std=0.1):\n",
        "    with tf.variable_scope(\"noise_layer\"):\n",
        "        return tensor + tf.random.normal(shape=tf.shape(tensor), mean=0.0, stddev=std, dtype=tf.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "More Functions\n"
      ],
      "metadata": {
        "id": "nIzjTPoKlFSJ"
      },
      "id": "nIzjTPoKlFSJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10207e24-45c5-4627-8653-328a93dbf5db",
      "metadata": {
        "id": "10207e24-45c5-4627-8653-328a93dbf5db"
      },
      "outputs": [],
      "source": [
        "import tensorflow_addons as tfa\n",
        "\n",
        "def get_loss_op(secret_true, secret_pred, cover_true, cover_pred, beta=0.5):\n",
        "    beta = tf.constant(beta, name=\"beta\")\n",
        "\n",
        "    # Calculate SSIM for secret and cover images\n",
        "    secret_ssim = 1 - tfa.image.ssim(secret_true, secret_pred, max_val=1.0)\n",
        "    cover_ssim = 1 - tfa.image.ssim(cover_true, cover_pred, max_val=1.0)\n",
        "\n",
        "    # Combine SSIM losses with weighting factor\n",
        "    final_loss = cover_ssim + beta * secret_ssim\n",
        "\n",
        "    return final_loss, secret_ssim, cover_ssim\n",
        "\n",
        "# additonal corr(Rc,S) losses can be adjusted where Rc = ||C-C'|| ,  S is Secret Image, C is Cover Image and C' is Container/Stego Image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TENSOR TO IMAGE FUNCTION"
      ],
      "metadata": {
        "id": "GSuSo8MDlc3H"
      },
      "id": "GSuSo8MDlc3H"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00d62072-51ab-42f4-bd5d-e93c511a1804",
      "metadata": {
        "id": "00d62072-51ab-42f4-bd5d-e93c511a1804"
      },
      "outputs": [],
      "source": [
        "def get_tensor_to_img_op(tensor):\n",
        "    # Normalization factors (mean and std)\n",
        "    mean = tf.constant([0.485, 0.456, 0.406])\n",
        "    std = tf.constant([0.229, 0.224, 0.225])\n",
        "\n",
        "    # Denormalize the tensor\n",
        "    t = tensor * std + mean\n",
        "\n",
        "    # Clip the values to the range [0, 1]\n",
        "    return tf.clip_by_value(t, 0, 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Related RESULTS"
      ],
      "metadata": {
        "id": "Yh4EM6iOl6qt"
      },
      "id": "Yh4EM6iOl6qt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5092ebfb-f4e3-4bb5-bc33-63c5fa068ba8",
      "metadata": {
        "id": "5092ebfb-f4e3-4bb5-bc33-63c5fa068ba8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def prepare_training_graph(secret_tensor, cover_tensor, global_step_tensor):\n",
        "    prep_output_op = get_prep_network_op(secret_tensor)\n",
        "    hiding_output_op = get_hiding_network_op(cover_tensor=cover_tensor, prep_output=prep_output_op)\n",
        "    noise_add_op = get_noise_layer_op(hiding_output_op)\n",
        "    reveal_output_op = get_reveal_network_op(noise_add_op)\n",
        "\n",
        "    loss_op, secret_loss_op, cover_loss_op = get_loss_op(secret_tensor, reveal_output_op, cover_tensor, hiding_output_op, beta=BETA)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
        "    minimize_op = optimizer.minimize(loss_op, global_step=global_step_tensor)\n",
        "\n",
        "    # Summary writers\n",
        "    summary_writer = tf.summary.create_file_writer('logs')\n",
        "\n",
        "    with summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', loss_op, step=global_step_tensor)\n",
        "        tf.summary.scalar('reveal_net_loss', secret_loss_op, step=global_step_tensor)\n",
        "        tf.summary.scalar('cover_net_loss', cover_loss_op, step=global_step_tensor)\n",
        "\n",
        "        tf.summary.image('secret', get_tensor_to_img_op(secret_tensor), step=global_step_tensor, max_outputs=1)\n",
        "        tf.summary.image('cover', get_tensor_to_img_op(cover_tensor), step=global_step_tensor, max_outputs=1)\n",
        "        tf.summary.image('hidden', get_tensor_to_img_op(hiding_output_op), step=global_step_tensor, max_outputs=1)\n",
        "        tf.summary.image('hidden_noisy', get_tensor_to_img_op(noise_add_op), step=global_step_tensor, max_outputs=1)\n",
        "        tf.summary.image('revealed', get_tensor_to_img_op(reveal_output_op), step=global_step_tensor, max_outputs=1)\n",
        "\n",
        "    merged_summary_op = summary_writer.flush()\n",
        "\n",
        "    return minimize_op, merged_summary_op\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST RESULTS"
      ],
      "metadata": {
        "id": "nYOp067pnS21"
      },
      "id": "nYOp067pnS21"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e7f7e6c-cc6d-4c37-87e6-c454992dcaa8",
      "metadata": {
        "id": "5e7f7e6c-cc6d-4c37-87e6-c454992dcaa8"
      },
      "outputs": [],
      "source": [
        "def prepare_test_graph(secret_tensor, cover_tensor):\n",
        "    prep_output_op = get_prep_network_op(secret_tensor)\n",
        "    hiding_output_op = get_hiding_network_op(cover_tensor=cover_tensor, prep_output=prep_output_op)\n",
        "    reveal_output_op = get_reveal_network_op(hiding_output_op)\n",
        "\n",
        "    loss_op, secret_loss_op, cover_loss_op = get_loss_op(secret_tensor, reveal_output_op, cover_tensor, hiding_output_op)\n",
        "\n",
        "    summary_writer = tf.summary.create_file_writer('logs/test')\n",
        "\n",
        "    with summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', loss_op, step=0)\n",
        "        tf.summary.scalar('reveal_net_loss', secret_loss_op, step=0)\n",
        "        tf.summary.scalar('cover_net_loss', cover_loss_op, step=0)\n",
        "\n",
        "        tf.summary.image('secret', get_tensor_to_img_op(secret_tensor), step=0, max_outputs=1)\n",
        "        tf.summary.image('cover', get_tensor_to_img_op(cover_tensor), step=0, max_outputs=1)\n",
        "        tf.summary.image('hidden', get_tensor_to_img_op(hiding_output_op), step=0, max_outputs=1)\n",
        "        tf.summary.image('revealed', get_tensor_to_img_op(reveal_output_op), step=0, max_outputs=1)\n",
        "\n",
        "        summary_writer.flush()\n",
        "\n",
        "    return summary_writer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment GRAPHS"
      ],
      "metadata": {
        "id": "VDhd_qEpnkmu"
      },
      "id": "VDhd_qEpnkmu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45093646-72ca-4d30-8125-1fc3f3fe9d4e",
      "metadata": {
        "id": "45093646-72ca-4d30-8125-1fc3f3fe9d4e"
      },
      "outputs": [],
      "source": [
        "def prepare_deployment_graph(secret_tensor, cover_tensor, covered_tensor):\n",
        "    # Get the outputs from each network operation\n",
        "    prep_output_op = get_pprep_network_op(secret_tensor)\n",
        "    hiding_output_op = get_hiding_network_op(cover_tensor=cover_tensor, prep_output=prep_output_op)\n",
        "    reveal_output_op = get_reveal_network_op(covered_tensor)\n",
        "\n",
        "    return hiding_output_op, reveal_output_op\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e3181b4-3c9a-49fb-af4a-be9f9e42223a",
      "metadata": {
        "id": "7e3181b4-3c9a-49fb-af4a-be9f9e42223a"
      },
      "outputs": [],
      "source": [
        "# Prepare training graph function\n",
        "def prepare_training_graph(secret_tensor, cover_tensor, global_step_tensor):\n",
        "    prep_output_op = get_prep_network_op(secret_tensor)\n",
        "    hiding_output_op = get_hiding_network_op(cover_tensor=cover_tensor, prep_output=prep_output_op)\n",
        "    noise_add_op = get_noise_layer_op(hiding_output_op)\n",
        "    reveal_output_op = get_reveal_network_op(noise_add_op)\n",
        "\n",
        "    loss_op, secret_loss_op, cover_loss_op = get_loss_op(secret_tensor, reveal_output_op, cover_tensor, hiding_output_op, beta=BETA)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
        "    minimize_op = optimizer.minimize(loss_op, global_step=global_step_tensor)\n",
        "\n",
        "    summary_writer = tf.summary.create_file_writer('logs/train')\n",
        "    with summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', loss_op, step=global_step_tensor)\n",
        "        tf.summary.scalar('reveal_net_loss', secret_loss_op, step=global_step_tensor)\n",
        "        tf.summary.scalar('cover_net_loss', cover_loss_op, step=global_step_tensor)\n",
        "        tf.summary.image('secret', get_tensor_to_img_op(secret_tensor), step=global_step_tensor, max_outputs=1)\n",
        "        tf.summary.image('cover', get_tensor_to_img_op(cover_tensor), step=global_step_tensor, max_outputs=1)\n",
        "        tf.summary.image('hidden', get_tensor_to_img_op(hiding_output_op), step=global_step_tensor, max_outputs=1)\n",
        "        tf.summary.image('hidden_noisy', get_tensor_to_img_op(noise_add_op), step=global_step_tensor, max_outputs=1)\n",
        "        tf.summary.image('revealed', get_tensor_to_img_op(reveal_output_op), step=global_step_tensor, max_outputs=1)\n",
        "        summary_writer.flush()\n",
        "\n",
        "    return minimize_op, summary_writer\n",
        "\n",
        "# Prepare test graph function\n",
        "def prepare_test_graph(secret_tensor, cover_tensor):\n",
        "    prep_output_op = get_prep_network_op(secret_tensor)\n",
        "    hiding_output_op = get_hiding_network_op(cover_tensor=cover_tensor, prep_output=prep_output_op)\n",
        "    reveal_output_op = get_reveal_network_op(hiding_output_op)\n",
        "\n",
        "    loss_op, secret_loss_op, cover_loss_op = get_loss_op(secret_tensor, reveal_output_op, cover_tensor, hiding_output_op)\n",
        "\n",
        "    summary_writer = tf.summary.create_file_writer('logs/test')\n",
        "    with summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', loss_op, step=0)\n",
        "        tf.summary.scalar('reveal_net_loss', secret_loss_op, step=0)\n",
        "        tf.summary.scalar('cover_net_loss', cover_loss_op, step=0)\n",
        "        tf.summary.image('secret', get_tensor_to_img_op(secret_tensor), step=0, max_outputs=1)\n",
        "        tf.summary.image('cover', get_tensor_to_img_op(cover_tensor), step=0, max_outputs=1)\n",
        "        tf.summary.image('hidden', get_tensor_to_img_op(hiding_output_op), step=0, max_outputs=1)\n",
        "        tf.summary.image('revealed', get_tensor_to_img_op(reveal_output_op), step=0, max_outputs=1)\n",
        "        summary_writer.flush()\n",
        "\n",
        "    return summary_writer\n",
        "\n",
        "# Prepare deployment graph function\n",
        "def prepare_deployment_graph(secret_tensor, cover_tensor, covered_tensor):\n",
        "    prep_output_op = get_prep_network_op(secret_tensor)\n",
        "    hiding_output_op = get_hiding_network_op(cover_tensor=cover_tensor, prep_output=prep_output_op)\n",
        "    reveal_output_op = get_reveal_network_op(covered_tensor)\n",
        "\n",
        "    return hiding_output_op, reveal_output_op\n",
        "\n",
        "# Define the model inputs using tf.TensorSpec\n",
        "def model_fn(secret_tensor_spec, cover_tensor_spec, covered_tensor_spec=None):\n",
        "    secret_tensor = tf.keras.Input(shape=secret_tensor_spec.shape[1:], dtype=secret_tensor_spec.dtype)\n",
        "    cover_tensor = tf.keras.Input(shape=cover_tensor_spec.shape[1:], dtype=cover_tensor_spec.dtype)\n",
        "    if covered_tensor_spec is not None:\n",
        "        covered_tensor = tf.keras.Input(shape=covered_tensor_spec.shape[1:], dtype=covered_tensor_spec.dtype)\n",
        "    else:\n",
        "        covered_tensor = None\n",
        "\n",
        "    global_step_tensor = tf.Variable(0, trainable=False, name='global_step')\n",
        "\n",
        "    train_op, train_summary_writer = prepare_training_graph(secret_tensor, cover_tensor, global_step_tensor)\n",
        "    test_summary_writer = prepare_test_graph(secret_tensor, cover_tensor)\n",
        "\n",
        "    if covered_tensor is not None:\n",
        "        deploy_hide_image_op, deploy_reveal_image_op = prepare_deployment_graph(secret_tensor, cover_tensor, covered_tensor)\n",
        "    else:\n",
        "        deploy_hide_image_op, deploy_reveal_image_op = None, None\n",
        "\n",
        "    return train_op, train_summary_writer, test_summary_writer, deploy_hide_image_op, deploy_reveal_image_op\n",
        "\n",
        "# Define the input specs\n",
        "secret_tensor_spec = tf.TensorSpec(shape=[None, 224, 224, 3], dtype=tf.float32, name=\"input_prep\")\n",
        "cover_tensor_spec = tf.TensorSpec(shape=[None, 224, 224, 3], dtype=tf.float32, name=\"input_hide\")\n",
        "covered_tensor_spec = tf.TensorSpec(shape=[None, 224, 224, 3], dtype=tf.float32, name=\"deploy_covered\")\n",
        "\n",
        "# Call the model function\n",
        "train_op, train_summary_writer, test_summary_writer, deploy_hide_image_op, deploy_reveal_image_op = model_fn(secret_tensor_spec, cover_tensor_spec, covered_tensor_spec)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c663c995-a77a-4eda-b628-b57480fb6bfd",
      "metadata": {
        "id": "c663c995-a77a-4eda-b628-b57480fb6bfd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1db85af5-22e4-46ba-b8e5-a182466c3040",
      "metadata": {
        "id": "1db85af5-22e4-46ba-b8e5-a182466c3040"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a69ae049-19eb-47f8-b9fb-60d5e0975303",
      "metadata": {
        "id": "a69ae049-19eb-47f8-b9fb-60d5e0975303"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "904f7b3e-e0af-4072-8157-11d40a686bc9",
      "metadata": {
        "id": "904f7b3e-e0af-4072-8157-11d40a686bc9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}